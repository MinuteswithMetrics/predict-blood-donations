{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__      import division\n",
    "from IPython.display import display\n",
    "from matplotlib      import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy  as np\n",
    "import pandas as pd\n",
    "import random, sys, os, re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The test set has duplicates so we get the list of IDs in the sample file in order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "id_list = []\n",
    "with open('../submissions/Submission_Format.csv', 'r') as f:\n",
    "    lines = f.read().splitlines()\n",
    "    for line in lines:\n",
    "        ID,prob = line.split(',')\n",
    "        if ID == '': continue\n",
    "        id_list.append(ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_filepaths(directory):\n",
    "    \"\"\"\n",
    "    This function will generate the file names in a directory \n",
    "    tree by walking the tree either top-down or bottom-up. For each \n",
    "    directory in the tree rooted at directory top (including top itself), \n",
    "    it yields a 3-tuple list (dirpath, dirnames, filenames).\n",
    "    \"\"\"\n",
    "    import os\n",
    "    \n",
    "    file_paths = []  # List which will store all of the full filepaths.\n",
    "\n",
    "    # Walk the tree.\n",
    "    for root, directories, files in os.walk(directory):\n",
    "        for filename in files:\n",
    "            # Join the two strings in order to form the full filepath.\n",
    "            filepath = os.path.join(root, filename)\n",
    "            file_paths.append(filepath)  # Add it to the list.\n",
    "\n",
    "    return file_paths "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the list of submission files \n",
    "\n",
    "* ## remove the example file \n",
    "* ## and all ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../submissions/submission_0.4457_LogisticRegressionCV.csv',\n",
       " '../submissions/submission_0.5670_SGDClassifier.csv',\n",
       " '../submissions/submission_1.7907_RandomForestClassifier.csv',\n",
       " '../submissions/submission_voting_ensemble_soft.csv',\n",
       " '../submissions/Submission_Format.csv',\n",
       " '../submissions/submission_EnsembleOfAveragesBEST.csv',\n",
       " '../submissions/submission_0.4885_BaggingClassifier.csv',\n",
       " '../submissions/submission_boosted_svc.csv',\n",
       " '../submissions/submission_0.4566_nolearn.csv',\n",
       " '../submissions/submission_voting_ensemble_hard.csv',\n",
       " '../submissions/submission_0.4851_XGBClassifier_vanilla.csv',\n",
       " '../submissions/submission_EnsembleOfAveragesALL.csv',\n",
       " '../submissions/submission_0.6642_AdaBoostClassifier.csv',\n",
       " '../submissions/submission_0.4411_LogisticRegression.csv',\n",
       " '../submissions/submission_0.5336_SVC.csv',\n",
       " '../submissions/submission_0.5732_cosine_similarity.csv',\n",
       " '../submissions/submission_0.4648_GradientBoostingClassifier_engineering.csv',\n",
       " '../submissions/submission_0.4608_GradientBoostingClassifier.csv',\n",
       " '../submissions/submission_bagged_gbc.csv',\n",
       " '../submissions/submission_0.4452_GradientBoostingClassifier_exponential.csv',\n",
       " '../submissions/submission_0.4896_EnsembleOfAverages.csv',\n",
       " '../submissions/submission_0.6289_KMeans.csv',\n",
       " '../submissions/submission_0.4729_ExtraTreesClassifier.csv',\n",
       " '../submissions/submission_1.1870_KNeighborsClassifier.csv']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list = get_filepaths('../submissions')\n",
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../submissions/submission_0.4457_LogisticRegressionCV.csv',\n",
       " '../submissions/submission_0.5670_SGDClassifier.csv',\n",
       " '../submissions/submission_1.7907_RandomForestClassifier.csv',\n",
       " '../submissions/submission_0.4885_BaggingClassifier.csv',\n",
       " '../submissions/submission_boosted_svc.csv',\n",
       " '../submissions/submission_0.4566_nolearn.csv',\n",
       " '../submissions/submission_0.4851_XGBClassifier_vanilla.csv',\n",
       " '../submissions/submission_0.6642_AdaBoostClassifier.csv',\n",
       " '../submissions/submission_0.4411_LogisticRegression.csv',\n",
       " '../submissions/submission_0.5336_SVC.csv',\n",
       " '../submissions/submission_0.5732_cosine_similarity.csv',\n",
       " '../submissions/submission_0.4648_GradientBoostingClassifier_engineering.csv',\n",
       " '../submissions/submission_0.4608_GradientBoostingClassifier.csv',\n",
       " '../submissions/submission_bagged_gbc.csv',\n",
       " '../submissions/submission_0.4452_GradientBoostingClassifier_exponential.csv',\n",
       " '../submissions/submission_0.6289_KMeans.csv',\n",
       " '../submissions/submission_0.4729_ExtraTreesClassifier.csv',\n",
       " '../submissions/submission_1.1870_KNeighborsClassifier.csv']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# why do it more than once? For some reason it doesn't work if only run once. Who knows?\n",
    "# ======================================================================================\n",
    "for i in range(3):\n",
    "    for file_name in file_list:\n",
    "        if 'Format'   in file_name: file_list.remove(file_name)\n",
    "        if 'Ensemble' in file_name: file_list.remove(file_name)\n",
    "        if 'ensemble' in file_name: file_list.remove(file_name)\n",
    "    \n",
    "file_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------- Ensemble ALL the submissions --------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "source": [
    "# Find the average probability for all IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['0.355096586523',\n",
       "  '0.35',\n",
       "  '0.1',\n",
       "  '0.252661172161',\n",
       "  '0.229568971977',\n",
       "  '0.458084821701',\n",
       "  '0.173246413469',\n",
       "  '0.494101309394',\n",
       "  '0.308123096572',\n",
       "  '0.201544480802',\n",
       "  '0.35',\n",
       "  '0.360423053959',\n",
       "  '0.40501948695',\n",
       "  '0.344323032548',\n",
       "  '0.296876234606',\n",
       "  '0.35',\n",
       "  '0.184227189057',\n",
       "  '0.222222222222'],\n",
       " 0.30197322621894451)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "aggregates = defaultdict(list)\n",
    "averages   = defaultdict(list)\n",
    "\n",
    "\n",
    "# 1. collect the probabilities for each ID from all the submission files\n",
    "# ======================================================================\n",
    "for file_name in file_list:\n",
    "    with open(file_name, 'r') as f:\n",
    "        lines = f.read().splitlines()\n",
    "        for line in lines:\n",
    "            ID,prob = line.split(',')\n",
    "            if ID == '': continue\n",
    "            aggregates[ID].append(prob)\n",
    "            \n",
    "        \n",
    "            \n",
    "# 2. find the average of all the probabilities for each ID\n",
    "# ========================================================\n",
    "averages.update((ID, np.mean(map(float, probs))) for ID, probs in aggregates.items())\n",
    "\n",
    "aggregates['1'],averages['1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(172, 172)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aggregates),len(averages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a submission file of the ensemble of averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open(\"../submissions/submission_EnsembleOfAveragesALL.csv\", \"w\")\n",
    "\n",
    "f.write(\",Made Donation in March 2007\\n\")\n",
    "for ID in id_list:\n",
    "    f.write(\"{},{}\\n\".format(ID, averages[ID]))\n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 192\r\n",
      "-rw-rw-r-- 1 george george 3826 Nov 14 18:55 submission_0.4411_LogisticRegression.csv\r\n",
      "-rw-rw-r-- 1 george george 3859 Nov 13 18:39 submission_0.4452_GradientBoostingClassifier_exponential.csv\r\n",
      "-rw-rw-r-- 1 george george 3821 Nov 14 19:12 submission_0.4457_LogisticRegressionCV.csv\r\n",
      "-rw-rw-r-- 1 george george 3814 Nov 13 16:09 submission_0.4566_nolearn.csv\r\n",
      "-rw-rw-r-- 1 george george 3849 Nov 11 15:46 submission_0.4608_GradientBoostingClassifier.csv\r\n",
      "-rw-rw-r-- 1 george george 3790 Nov 13 10:49 submission_0.4648_GradientBoostingClassifier_engineering.csv\r\n",
      "-rw-rw-r-- 1 george george 3798 Nov 11 19:28 submission_0.4729_ExtraTreesClassifier.csv\r\n",
      "-rw-rw-r-- 1 george george 3835 Nov 11 15:14 submission_0.4851_XGBClassifier_vanilla.csv\r\n",
      "-rw-rw-r-- 1 george george 3701 Nov 14 10:03 submission_0.4885_BaggingClassifier.csv\r\n",
      "-rw-rw-r-- 1 george george 3829 Nov 11 18:35 submission_0.4896_EnsembleOfAverages.csv\r\n",
      "-rw-rw-r-- 1 george george 3787 Nov 14 15:22 submission_0.5336_SVC.csv\r\n",
      "-rw-rw-r-- 1 george george 1800 Nov 13 08:52 submission_0.5670_SGDClassifier.csv\r\n",
      "-rw-rw-r-- 1 george george 1800 Nov 13 18:26 submission_0.5732_cosine_similarity.csv\r\n",
      "-rw-rw-r-- 1 george george 1800 Nov 13 14:29 submission_0.6289_KMeans.csv\r\n",
      "-rw-rw-r-- 1 george george 3784 Nov 13 12:12 submission_0.6642_AdaBoostClassifier.csv\r\n",
      "-rw-rw-r-- 1 george george 3437 Nov 13 08:32 submission_1.1870_KNeighborsClassifier.csv\r\n",
      "-rw-rw-r-- 1 george george 2283 Nov 11 16:51 submission_1.7907_RandomForestClassifier.csv\r\n",
      "-rw-rw-r-- 1 george george 3847 Nov 15 16:13 submission_bagged_gbc.csv\r\n",
      "-rw-rw-r-- 1 george george 3756 Nov 15 17:11 submission_boosted_svc.csv\r\n",
      "-rw-rw-r-- 1 george george 3782 Nov 15 20:14 submission_EnsembleOfAveragesALL.csv\r\n",
      "-rw-rw-r-- 1 george george 3806 Nov 15 20:13 submission_EnsembleOfAveragesBEST.csv\r\n",
      "-rw-r----- 1 george george 1600 Nov  9 19:00 Submission_Format.csv\r\n",
      "-rw-rw-r-- 1 george george 1800 Nov 15 19:59 submission_voting_ensemble_hard.csv\r\n",
      "-rw-rw-r-- 1 george george 3795 Nov 15 19:58 submission_voting_ensemble_soft.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l ../submissions/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# ---------- Ensemble the submissions with a score of 0.4... or 0.3... ----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../submissions/submission_0.4457_LogisticRegressionCV.csv',\n",
       " '../submissions/submission_0.5670_SGDClassifier.csv',\n",
       " '../submissions/submission_1.7907_RandomForestClassifier.csv',\n",
       " '../submissions/submission_0.4885_BaggingClassifier.csv',\n",
       " '../submissions/submission_boosted_svc.csv',\n",
       " '../submissions/submission_0.4566_nolearn.csv',\n",
       " '../submissions/submission_0.4851_XGBClassifier_vanilla.csv',\n",
       " '../submissions/submission_0.6642_AdaBoostClassifier.csv',\n",
       " '../submissions/submission_0.4411_LogisticRegression.csv',\n",
       " '../submissions/submission_0.5336_SVC.csv',\n",
       " '../submissions/submission_0.5732_cosine_similarity.csv',\n",
       " '../submissions/submission_0.4648_GradientBoostingClassifier_engineering.csv',\n",
       " '../submissions/submission_0.4608_GradientBoostingClassifier.csv',\n",
       " '../submissions/submission_bagged_gbc.csv',\n",
       " '../submissions/submission_0.4452_GradientBoostingClassifier_exponential.csv',\n",
       " '../submissions/submission_0.6289_KMeans.csv',\n",
       " '../submissions/submission_0.4729_ExtraTreesClassifier.csv',\n",
       " '../submissions/submission_1.1870_KNeighborsClassifier.csv']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../submissions/submission_0.4457_LogisticRegressionCV.csv',\n",
       " '../submissions/submission_0.4885_BaggingClassifier.csv',\n",
       " '../submissions/submission_0.4566_nolearn.csv',\n",
       " '../submissions/submission_0.4851_XGBClassifier_vanilla.csv',\n",
       " '../submissions/submission_0.4411_LogisticRegression.csv',\n",
       " '../submissions/submission_0.4648_GradientBoostingClassifier_engineering.csv',\n",
       " '../submissions/submission_0.4608_GradientBoostingClassifier.csv',\n",
       " '../submissions/submission_0.4452_GradientBoostingClassifier_exponential.csv',\n",
       " '../submissions/submission_0.4729_ExtraTreesClassifier.csv']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# why do it more than once? For some reason it doesn't work if only run once. Who knows?\n",
    "# ======================================================================================\n",
    "for i in range(3):\n",
    "    for file_name in file_list:\n",
    "        if 'Format'   in file_name: file_list.remove(file_name)\n",
    "        if 'Ensemble' in file_name: file_list.remove(file_name)\n",
    "\n",
    "        # scores of 0.4... or 0.3... are good\n",
    "        # files with SEED... are good-scoring models that were re-run with different random seeds\n",
    "        if ('0.4' not  in file_name) and \\\n",
    "           ('0.3' not  in file_name) and \\\n",
    "           ('SEED' not in file_name):       \n",
    "                file_list.remove(file_name)\n",
    "    \n",
    "file_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['0.355096586523',\n",
       "  '0.252661172161',\n",
       "  '0.458084821701',\n",
       "  '0.173246413469',\n",
       "  '0.308123096572',\n",
       "  '0.360423053959',\n",
       "  '0.40501948695',\n",
       "  '0.296876234606',\n",
       "  '0.184227189057'],\n",
       " 0.31041756166644446)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "aggregates = defaultdict(list)\n",
    "averages   = defaultdict(list)\n",
    "\n",
    "\n",
    "# 1. collect the probabilities for each ID from all the submission files\n",
    "# ======================================================================\n",
    "for file_name in file_list:\n",
    "    with open(file_name, 'r') as f:\n",
    "        lines = f.read().splitlines()\n",
    "        for line in lines:\n",
    "            ID,prob = line.split(',')\n",
    "            if ID == '': continue\n",
    "            aggregates[ID].append(prob)\n",
    "            \n",
    "        \n",
    "            \n",
    "# 2. find the average of all the probabilities for each ID\n",
    "# ========================================================\n",
    "averages.update((ID, np.mean(map(float, probs))) for ID, probs in aggregates.items())\n",
    "\n",
    "aggregates['1'],averages['1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(172, 172)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(aggregates),len(averages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "f = open(\"../submissions/submission_EnsembleOfAveragesBEST.csv\", \"w\")\n",
    "\n",
    "f.write(\",Made Donation in March 2007\\n\")\n",
    "for ID in id_list:\n",
    "    f.write(\"{},{}\\n\".format(ID, averages[ID]))\n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 192\r\n",
      "-rw-rw-r-- 1 george george 3826 Nov 14 18:55 submission_0.4411_LogisticRegression.csv\r\n",
      "-rw-rw-r-- 1 george george 3859 Nov 13 18:39 submission_0.4452_GradientBoostingClassifier_exponential.csv\r\n",
      "-rw-rw-r-- 1 george george 3821 Nov 14 19:12 submission_0.4457_LogisticRegressionCV.csv\r\n",
      "-rw-rw-r-- 1 george george 3814 Nov 13 16:09 submission_0.4566_nolearn.csv\r\n",
      "-rw-rw-r-- 1 george george 3849 Nov 11 15:46 submission_0.4608_GradientBoostingClassifier.csv\r\n",
      "-rw-rw-r-- 1 george george 3790 Nov 13 10:49 submission_0.4648_GradientBoostingClassifier_engineering.csv\r\n",
      "-rw-rw-r-- 1 george george 3798 Nov 11 19:28 submission_0.4729_ExtraTreesClassifier.csv\r\n",
      "-rw-rw-r-- 1 george george 3835 Nov 11 15:14 submission_0.4851_XGBClassifier_vanilla.csv\r\n",
      "-rw-rw-r-- 1 george george 3701 Nov 14 10:03 submission_0.4885_BaggingClassifier.csv\r\n",
      "-rw-rw-r-- 1 george george 3829 Nov 11 18:35 submission_0.4896_EnsembleOfAverages.csv\r\n",
      "-rw-rw-r-- 1 george george 3787 Nov 14 15:22 submission_0.5336_SVC.csv\r\n",
      "-rw-rw-r-- 1 george george 1800 Nov 13 08:52 submission_0.5670_SGDClassifier.csv\r\n",
      "-rw-rw-r-- 1 george george 1800 Nov 13 18:26 submission_0.5732_cosine_similarity.csv\r\n",
      "-rw-rw-r-- 1 george george 1800 Nov 13 14:29 submission_0.6289_KMeans.csv\r\n",
      "-rw-rw-r-- 1 george george 3784 Nov 13 12:12 submission_0.6642_AdaBoostClassifier.csv\r\n",
      "-rw-rw-r-- 1 george george 3437 Nov 13 08:32 submission_1.1870_KNeighborsClassifier.csv\r\n",
      "-rw-rw-r-- 1 george george 2283 Nov 11 16:51 submission_1.7907_RandomForestClassifier.csv\r\n",
      "-rw-rw-r-- 1 george george 3847 Nov 15 16:13 submission_bagged_gbc.csv\r\n",
      "-rw-rw-r-- 1 george george 3756 Nov 15 17:11 submission_boosted_svc.csv\r\n",
      "-rw-rw-r-- 1 george george 3782 Nov 15 20:14 submission_EnsembleOfAveragesALL.csv\r\n",
      "-rw-rw-r-- 1 george george 3806 Nov 15 20:14 submission_EnsembleOfAveragesBEST.csv\r\n",
      "-rw-r----- 1 george george 1600 Nov  9 19:00 Submission_Format.csv\r\n",
      "-rw-rw-r-- 1 george george 1800 Nov 15 19:59 submission_voting_ensemble_hard.csv\r\n",
      "-rw-rw-r-- 1 george george 3795 Nov 15 19:58 submission_voting_ensemble_soft.csv\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l ../submissions/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
